{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup main dataframe, initial column is [\"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\", \"DIAGNOSIS\"] from ADMISSIONS\n",
    "# SUBJECT_ID: Each patient has unique ID\n",
    "# HADM_ID: Each admission has unique ID\n",
    "# ADMITTIME: The date and time the patient was admitted to the hospital\n",
    "# DIAGNOSIS: The primary diagnosis of the patient\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 0)\n",
    "\n",
    "# read ADMISSIONS.csv.gz\n",
    "mainDF = pd.read_csv('../mimic-iii-clinical-database-1.4/ADMISSIONS.csv.gz', compression='gzip', usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\", \"DIAGNOSIS\"])\n",
    "\n",
    "# Change the ADMITTIME only have date\n",
    "mainDF[\"ADMITTIME\"] = pd.to_datetime(mainDF[\"ADMITTIME\"]).dt.date.astype(str)\n",
    "\n",
    "# Dtop the rows if DIAGNOSIS is NaN\n",
    "mainDF = mainDF.dropna(subset=[\"DIAGNOSIS\"])\n",
    "\n",
    "# Separate the DIAGNOSIS if there are multiple, and output to dataframe\n",
    "data = []\n",
    "for row in mainDF.itertuples():\n",
    "\n",
    "  if \"\\\\\" in row.DIAGNOSIS:\n",
    "    diagnosisString = row.DIAGNOSIS.split(\"\\\\\")[0]\n",
    "  else:\n",
    "    diagnosisString = row.DIAGNOSIS\n",
    "  \n",
    "  if \";\" in diagnosisString:\n",
    "    diagnosisArray = diagnosisString.split(\";\")\n",
    "  else:\n",
    "    diagnosisArray = [diagnosisString]\n",
    "\n",
    "  for d in diagnosisArray:\n",
    "    data.append([row.SUBJECT_ID, row.HADM_ID, row.ADMITTIME, d])\n",
    "\n",
    "diagnosisDF = pd.DataFrame(data, columns=[\"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\", \"DIAGNOSIS\"])\n",
    "diagnosisDF.to_csv(\"diagnosis_0.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Lu\\AppData\\Local\\Temp\\ipykernel_24764\\1192727780.py:10: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  CHARTEVENTS = pd.read_csv('../mimic-iii-clinical-database-1.4/CHARTEVENTS.csv.gz', compression='gzip', usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"]).dropna()\n"
     ]
    }
   ],
   "source": [
    "# Add the height and weight to the main dataframe by using the [\"SUBJECT_ID\", \"HADM_ID\", \"ITEMID\", \"VALUE\"] in CHARTEVENTS\n",
    "# SUBJECT_ID: Each patient has unique ID\n",
    "# HADM_ID: Each admission has unique ID\n",
    "# ITEMID: weight index : 762, 763, 3723, 3580, 3581, 3582\n",
    "#         height index : 920, 1394, 4187, 3486, 3485, 4188\n",
    "# VALUE: the value of the ITEMID\n",
    "\n",
    "diagnosisDF = pd.read_csv(\"diagnosis_0.csv\")\n",
    "# read CHARTEVENTS.csv.gz and drop the missing value, and change the CHARTTIME only have date\n",
    "CHARTEVENTS = pd.read_csv('../mimic-iii-clinical-database-1.4/CHARTEVENTS.csv.gz', compression='gzip', usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"]).dropna()\n",
    "CHARTEVENTS[\"CHARTTIME\"] = pd.to_datetime(CHARTEVENTS[\"CHARTTIME\"]).dt.date.astype(str)\n",
    "\n",
    "# create weightHeightDict with key = (SUBJECT_ID, HADM_ID, CHARTTIME) and value = [weight, height]\n",
    "weightHeightDict = {}\n",
    "for row in CHARTEVENTS.itertuples():\n",
    "  key = (row.SUBJECT_ID, row.HADM_ID, row.CHARTTIME)\n",
    "\n",
    "  if row.ITEMID == 762 or row.ITEMID == 763 or row.ITEMID == 3723 or row.ITEMID == 3580: # weight unit is alreayd in KG\n",
    "    if key in weightHeightDict and weightHeightDict[key][0] == -1: weightHeightDict[key][0] = float(row.VALUE)\n",
    "    else: weightHeightDict[key] = [float(row.VALUE), -1]\n",
    "  \n",
    "  elif row.ITEMID == 3581: # weight unit is in LB\n",
    "    if key in weightHeightDict and weightHeightDict[key][0] == -1: weightHeightDict[key][0] = float(row.VALUE)*0.4536\n",
    "    else: weightHeightDict[key] = [float(row.VALUE)*0.4536, -1]\n",
    "  \n",
    "  elif row.ITEMID == 3582: # weight unit is in OZ\n",
    "    if key in weightHeightDict and weightHeightDict[key][0] == -1: weightHeightDict[key][0] = float(row.VALUE)*0.0283\n",
    "    else: weightHeightDict[key] = [float(row.VALUE)*0.0283, -1]\n",
    "  \n",
    "  elif row.ITEMID == 920 or row.ITEMID == 1394 or row.ITEMID == 4187 or row.ITEMID == 3486: # height unit is in inches\n",
    "    if key in weightHeightDict and weightHeightDict[key][1] == -1: weightHeightDict[key][1] = float(row.VALUE)*0.0254\n",
    "    else: weightHeightDict[key] = [-1, float(row.VALUE)*0.0254]\n",
    "\n",
    "  elif row.ITEMID == 3485 or row.ITEMID == 4188: # height unit is in cm\n",
    "    if key in weightHeightDict and weightHeightDict[key][1] == -1: weightHeightDict[key][1] = float(row.VALUE)*0.01\n",
    "    else: weightHeightDict[key] = [-1, float(row.VALUE)*0.01]\n",
    "\n",
    "# filter out if the key only have weight or height\n",
    "for key, value in list(weightHeightDict.items()):\n",
    "  if value[0] == -1 or value[1] == -1:\n",
    "    del weightHeightDict[key]\n",
    "\n",
    "# Plug the weight and height to the main dataframe\n",
    "for row in diagnosisDF.itertuples():\n",
    "  if (row.SUBJECT_ID, row.HADM_ID, row.ADMITTIME) in weightHeightDict:\n",
    "    weight, height = weightHeightDict[(row.SUBJECT_ID, row.HADM_ID, row.ADMITTIME)]\n",
    "    diagnosisDF.at[row.Index, \"WEIGHT\"] = weight\n",
    "    diagnosisDF.at[row.Index, \"HEIGHT\"] = height\n",
    "\n",
    "# Drop the rows if the weight or height is NaN\n",
    "diagnosisDF = diagnosisDF.dropna()\n",
    "\n",
    "diagnosisDF.to_csv(\"diagnosis_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Lu\\AppData\\Local\\Temp\\ipykernel_24764\\1414719692.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'M' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  diagnosisDF.at[row.Index, \"GENDER\"] = patientGender[row.SUBJECT_ID]\n"
     ]
    }
   ],
   "source": [
    "# Add the age and gender to the main dataframe by using the [\"SUBJECT_ID\", \"GENDER\", \"DOB\"] in PATIENTS\n",
    "# SUBJECT_ID: Each patient has unique ID\n",
    "# GENDER: patient's gender\n",
    "# DOB: patient's date of birth\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "diagnosisDF = pd.read_csv(\"diagnosis_1.csv\")\n",
    "\n",
    "# read PATIENTS.csv.gz and change the DOB only have date\n",
    "PATIENTS = pd.read_csv('../mimic-iii-clinical-database-1.4/PATIENTS.csv.gz', compression='gzip')\n",
    "PATIENTS[\"DOB\"] = pd.to_datetime(PATIENTS[\"DOB\"]).dt.date.astype(str)\n",
    "\n",
    "# create two dictionary with key = SUBJECT\n",
    "patientBrith = dict(zip(PATIENTS[\"SUBJECT_ID\"], PATIENTS[\"DOB\"]))\n",
    "patientGender = dict(zip(PATIENTS[\"SUBJECT_ID\"], PATIENTS[\"GENDER\"]))\n",
    "\n",
    "# Plug the Gender to the main dataframe\n",
    "for row in diagnosisDF.itertuples():\n",
    "  diagnosisDF.at[row.Index, \"GENDER\"] = patientGender[row.SUBJECT_ID]\n",
    "\n",
    "# Plug the Age to the main dataframe\n",
    "for row in diagnosisDF.itertuples():\n",
    "  admitYear, admitMonth, admitDate = row.ADMITTIME.split(\"-\")\n",
    "  birthYear, birthMonth, birthDate = patientBrith[row.SUBJECT_ID].split(\"-\")\n",
    "  patientMonth = int(admitYear)*12+int(admitMonth) - int(birthYear)*12+int(birthMonth)\n",
    "  age, remainder = patientMonth//12, patientMonth%12\n",
    "  if remainder >= 6: age += 1\n",
    "  diagnosisDF.at[row.Index, \"AGE\"] = int(age)\n",
    "\n",
    "# Drop the SUBJECT_ID, HADM_ID, ADMITTIME, since it is not needed anymore\n",
    "diagnosisDF = diagnosisDF.drop(columns=[\"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\"])\n",
    "\n",
    "diagnosisDF.to_csv(\"diagnosis_2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the typo in the data\n",
    "diagnosisDF = pd.read_csv(\"diagnosis_2.csv\")\n",
    "for index, row in enumerate(diagnosisDF.itertuples()):\n",
    "  original = row.DIAGNOSIS\n",
    "\n",
    "  if original == \"CORNARY ARTERY DISEASE\":\n",
    "    original = \"CORONARY ARTERY DISEASE\"\n",
    "    continue\n",
    "  elif original == \"\":\n",
    "    diagnosisDF.drop(index, inplace=True)\n",
    "    continue\n",
    "  \n",
    "  while original[0] == \" \" or original[0] == \"\\\"\" :\n",
    "    original = original[1:]\n",
    "  while original[-1] == \" \" or original[-1] == \"\\\"\":\n",
    "    original = original[:-1]\n",
    "  diagnosisDF.at[index, \"DIAGNOSIS\"] = original\n",
    "\n",
    "# drop the age > 150, don't know why the age is so high\n",
    "for row in diagnosisDF.itertuples():\n",
    "  if row.AGE > 150:\n",
    "    diagnosisDF.drop(row.Index, inplace=True)\n",
    "    \n",
    "diagnosisDF.to_csv(\"diagnosis_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish saving the diagnosisLabelToInt.pkl and diagnosisIntToLabel.pkl\n"
     ]
    }
   ],
   "source": [
    "# This section is do the feature extraction, and save the feature extraction to pickle\n",
    "import pickle\n",
    "\n",
    "diagnosisDF = pd.read_csv(\"diagnosis_3.csv\")\n",
    "\n",
    "# Do feature extraction on Diagnosis and Gender, and save it to pickle\n",
    "diagnosisLabelToInt = dict([(d, index) for index, d in enumerate(set(diagnosisDF[\"DIAGNOSIS\"]))])\n",
    "diagnosisIntToLabel = dict([(index, d) for index, d in enumerate(set(diagnosisDF[\"DIAGNOSIS\"]))])\n",
    "with open('../pickleFiles/diagnosisLabelToInt.pkl', 'wb') as f:\n",
    "  pickle.dump(diagnosisLabelToInt, f)\n",
    "with open('../pickleFiles/diagnosisIntToLabel.pkl', 'wb') as f:\n",
    "  pickle.dump(diagnosisIntToLabel, f)\n",
    "print(f'Finish saving the diagnosisLabelToInt.pkl and diagnosisIntToLabel.pkl')\n",
    "\n",
    "genderLabel = {\"M\": 0, \"F\": 1}\n",
    "diagnosisDF[\"DIAGNOSIS\"] = [diagnosisLabelToInt[n] for n in diagnosisDF[\"DIAGNOSIS\"]]\n",
    "diagnosisDF[\"GENDER\"] = [genderLabel[n] for n in diagnosisDF[\"GENDER\"]]\n",
    "\n",
    "diagnosisDF.to_csv('diagnosis_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    }
   ],
   "source": [
    "# This section is scale the X and then save the dataframe to csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diagnosisDF = pd.read_csv('./diagnosis_4.csv')\n",
    "\n",
    "y = diagnosisDF[\"DIAGNOSIS\"]\n",
    "X = diagnosisDF.drop([\"DIAGNOSIS\"], axis=1)\n",
    "Xcolumn = X.columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# save scaler to pickle\n",
    "with open('../pickleFiles/scaler.pkl', 'wb') as f:\n",
    "  pickle.dump(scaler, f)\n",
    "\n",
    "# save X to dataframe, and add y back, then drop the NaN\n",
    "X = pd.DataFrame(X, columns=Xcolumn)\n",
    "X[\"DIAGNOSIS\"] = y\n",
    "X = X.dropna()\n",
    "print(len(X))\n",
    "# save X to the csv file\n",
    "X.to_csv('diagnosis_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
